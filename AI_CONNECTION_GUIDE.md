# ğŸ¤– Przewodnik PoÅ‚Ä…czenia AI

## âœ… **Status: PoÅ‚Ä…czenie AI Gotowe!**

Twoje AI jest teraz w peÅ‚ni poÅ‚Ä…czone z aplikacjÄ… Streamlit. Oto jak to dziaÅ‚a:

## ğŸš€ **Jak uruchomiÄ‡ system z AI**

### **Krok 1: Uruchom serwer AI**
```bash
# Aktywuj Å›rodowisko wirtualne
source venv/bin/activate

# Uruchom serwer AI (w osobnym terminalu)
./start_ai_server.sh
```

**Co siÄ™ dzieje:**
- âœ… Åaduje model Llama 3 8B na RTX 4090
- âœ… Uruchamia API na porcie 8000
- âœ… Model gotowy w ~30 sekund

### **Krok 2: Uruchom Streamlit z AI**
```bash
# W nowym terminalu
source venv/bin/activate
./start_streamlit_with_ai.sh
```

**Co siÄ™ dzieje:**
- âœ… ÅÄ…czy siÄ™ z serwerem AI na localhost:8000
- âœ… Uruchamia Streamlit na porcie 8501
- âœ… AI dziaÅ‚a w trybie rzeczywistym

## ğŸŒ **DostÄ™p do aplikacji**

- **Panel Streamlit**: http://localhost:8501
- **API AI**: http://localhost:8000
- **Status AI**: http://localhost:8000/healthz
- **GotowoÅ›Ä‡ modelu**: http://localhost:8000/ready

## ğŸ”§ **Jak dziaÅ‚a poÅ‚Ä…czenie**

### **Architektura:**
```
[Streamlit UI] â†â†’ [AI Server] â†â†’ [Llama 3 Model]
    8501             8000           RTX 4090
```

### **Funkcje AI:**
1. **ZakÅ‚adka "Audytor"** - AI asystent w kaÅ¼dej podzakÅ‚adce
2. **Analiza Sprawozdania** - specjalistyczne odpowiedzi o analizie finansowej
3. **Ocena Ryzyka** - ekspert w ocenie ryzyk audytowych
4. **Fallback** - jeÅ›li AI niedostÄ™pny, uÅ¼ywa inteligentnych odpowiedzi przykÅ‚adowych

### **Parametry AI:**
- **Model**: Llama 3 8B Instruct
- **Temperatura**: 0.8 (bardziej naturalne odpowiedzi)
- **Max tokens**: 512
- **Quantization**: 4-bit (oszczÄ™dnoÅ›Ä‡ pamiÄ™ci)

## ğŸ“Š **Status AI w aplikacji**

W sidebarze widzisz:
- âœ… **AI Model gotowy** - model zaÅ‚adowany i gotowy
- â³ **AI Model siÄ™ dogrzewa** - model siÄ™ Å‚aduje
- âŒ **Serwer AI niedostÄ™pny** - brak poÅ‚Ä…czenia

## ğŸ› ï¸ **RozwiÄ…zywanie problemÃ³w**

### **Problem: "Serwer AI niedostÄ™pny"**
```bash
# SprawdÅº czy serwer dziaÅ‚a
curl http://localhost:8000/healthz

# JeÅ›li nie dziaÅ‚a, uruchom ponownie
./start_ai_server.sh
```

### **Problem: "Model siÄ™ dogrzewa"**
- Poczekaj ~30 sekund na zaÅ‚adowanie modelu
- SprawdÅº status: http://localhost:8000/ready

### **Problem: Brak GPU**
- Model bÄ™dzie dziaÅ‚aÅ‚ na CPU (wolniej)
- Zainstaluj sterowniki NVIDIA + CUDA

### **Problem: Brak pamiÄ™ci GPU**
```bash
# SprawdÅº uÅ¼ycie GPU
nvidia-smi

# Model uÅ¼ywa ~12GB VRAM (4-bit quantization)
```

## ğŸ¯ **Testowanie AI**

### **Test 1: Podstawowy**
1. OtwÃ³rz http://localhost:8501
2. PrzejdÅº do zakÅ‚adki "ğŸ” Audytor"
3. Wybierz "ğŸ“Š Analiza Sprawozdania"
4. Zadaj pytanie: "Jakie sÄ… gÅ‚Ã³wne wskaÅºniki pÅ‚ynnoÅ›ci?"

### **Test 2: Zaawansowany**
1. Wybierz "âš ï¸ Ocena Ryzyka"
2. Zadaj pytanie: "Jak oceniÄ‡ ryzyko kontroli wewnÄ™trznej?"
3. SprawdÅº czy odpowiedÅº jest naturalna i szczegÃ³Å‚owa

## ğŸ”„ **Aktualizacje**

### **Aktualizacja modelu:**
```bash
# Zatrzymaj serwer (Ctrl+C)
# Zaktualizuj model w model_hf_interface.py
# Uruchom ponownie
./start_ai_server.sh
```

### **Aktualizacja temperatury:**
- Edytuj `temperature=0.8` w `streamlit_app.py`
- Restart Streamlit

## ğŸ“ˆ **WydajnoÅ›Ä‡**

### **Czasy odpowiedzi:**
- **Proste pytania**: 2-5 sekund
- **ZÅ‚oÅ¼one analizy**: 5-15 sekund
- **Timeout**: 30 sekund

### **Ograniczenia:**
- **Max tokens**: 512 (moÅ¼na zwiÄ™kszyÄ‡)
- **Concurrent requests**: 1 (moÅ¼na zwiÄ™kszyÄ‡)
- **Memory**: ~12GB VRAM

## ğŸš€ **WdroÅ¼enie na Streamlit Cloud**

Aby wdroÅ¼yÄ‡ na https://ai-auditor-86.streamlit.app/:

1. **Opcja 1: Cloudflare Tunnel**
   ```bash
   # Uruchom lokalny serwer AI
   ./start_ai_server.sh

   # Skonfiguruj Cloudflare Tunnel
   cloudflared tunnel create ai-auditor
   cloudflared tunnel route dns ai-auditor ai-auditor-86.streamlit.app
   ```

2. **Opcja 2: Hugging Face Inference API**
   - WdrÃ³Å¼ model na Hugging Face
   - ZmieÅ„ `AI_SERVER_URL` w Streamlit

3. **Opcja 3: Mock Mode**
   - Aplikacja automatycznie uÅ¼ywa mock responses
   - AI dziaÅ‚a w trybie przykÅ‚adowym

## âœ… **Podsumowanie**

Twoje AI jest teraz w peÅ‚ni funkcjonalne!

**Co masz:**
- âœ… Prawdziwy model Llama 3 8B
- âœ… Naturalne odpowiedzi (temperatura 0.8)
- âœ… Specjalistyczne AI dla audytu
- âœ… Fallback na mock responses
- âœ… Status AI w czasie rzeczywistym
- âœ… Åatwe uruchamianie (2 skrypty)

**NastÄ™pne kroki:**
1. Uruchom `./start_ai_server.sh`
2. Uruchom `./start_streamlit_with_ai.sh`
3. OtwÃ³rz http://localhost:8501
4. Przetestuj AI w zakÅ‚adce "Audytor"

**Gotowe! ğŸ‰**
