# ğŸš€ Konfiguracja AI przez Tunel Localtunnel

## âœ… **Status: GOTOWE**

Twoje lokalne AI jest teraz dostÄ™pne publicznie przez tunel!

## ğŸ”— **URL Twojego AI:**
```
https://ai-auditor-romaks.loca.lt
```

## ğŸ¯ **Jak to dziaÅ‚a:**

1. **Lokalnie**: AI server dziaÅ‚a na `http://localhost:8000`
2. **Tunel**: Localtunnel przekierowuje ruch z `https://ai-auditor-romaks.loca.lt` na lokalny port 8000
3. **Streamlit Cloud**: Aplikacja na `https://ai-auditor-86.streamlit.app/` uÅ¼ywa publicznego URL AI

## ğŸš€ **Uruchomienie (wymagane):**

### **Krok 1: Uruchom AI Server**
```bash
cd /home/romaks/ai_2/ai-auditor
source venv/bin/activate
uvicorn server:app --host 0.0.0.0 --port 8000 --reload
```

### **Krok 2: Uruchom Tunel (w nowym terminalu)**
```bash
cd /home/romaks/ai_2/ai-auditor
lt --port 8000 --subdomain ai-auditor-romaks
```

### **Krok 3: SprawdÅº czy dziaÅ‚a**
```bash
curl https://ai-auditor-romaks.loca.lt/healthz
curl https://ai-auditor-romaks.loca.lt/ready
```

## ğŸŒ **Testowanie:**

1. **OtwÃ³rz**: https://ai-auditor-86.streamlit.app/
2. **SprawdÅº AI Status** - powinien pokazywaÄ‡ "âœ… AI Model gotowy"
3. **Przetestuj chat** - zadaj pytanie w sekcji "Analiza Sprawozdania"

## âš ï¸ **WaÅ¼ne:**

- **Tunel musi byÄ‡ aktywny** - jeÅ›li go zamkniesz, AI przestanie dziaÅ‚aÄ‡ na stronie
- **AI Server musi dziaÅ‚aÄ‡** - tunel tylko przekierowuje ruch
- **URL tunelu** moÅ¼e siÄ™ zmieniÄ‡ przy restarcie (ale subdomain `ai-auditor-romaks` powinien zostaÄ‡)

## ğŸ”§ **Troubleshooting:**

### **Problem: "Serwer AI niedostÄ™pny"**
```bash
# SprawdÅº czy AI server dziaÅ‚a
curl http://localhost:8000/healthz

# SprawdÅº czy tunel dziaÅ‚a
curl https://ai-auditor-romaks.loca.lt/healthz
```

### **Problem: "Model siÄ™ dogrzewa"**
- Poczekaj 2-3 minuty po uruchomieniu AI servera
- Model Llama 3 8B potrzebuje czasu na zaÅ‚adowanie

### **Problem: Tunel nie dziaÅ‚a**
```bash
# Restart tunelu
pkill -f localtunnel
lt --port 8000 --subdomain ai-auditor-romaks
```

## ğŸ“Š **Status EndpointÃ³w:**

- âœ… `/healthz` - podstawowe "Å¼yjÄ™"
- âœ… `/ready` - status modelu
- âœ… `/analyze` - gÅ‚Ã³wny endpoint AI

## ğŸ‰ **Gotowe!**

Twoje lokalne AI jest teraz dostÄ™pne na stronie projektowej!
